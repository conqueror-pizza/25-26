{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adfe4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dense_Layer:\n",
    "    def __init__(self, inputs, weights, bias):\n",
    "        self.inputs = np.array(inputs)\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = np.array(bias)\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self):\n",
    "        inp = np.array(self.inputs)\n",
    "        weight = np.array(self.weights)\n",
    "        bias = np.array(self.bias)\n",
    "\n",
    "        if weight.ndim != 2:\n",
    "            raise ValueError(\"weights must be a 2D array\")\n",
    "\n",
    "        n_in = inp.shape[-1]  # number of input features\n",
    "        # Case A: weights shaped (n_in, n_out) -> use inp . W\n",
    "        if weight.shape[0] == n_in:\n",
    "            out = np.dot(inp, weight)\n",
    "        # Case B: weights shaped (n_out, n_in) -> use W . inp\n",
    "        elif weight.shape[1] == n_in:\n",
    "            out = np.dot(weight, inp)\n",
    "        else:\n",
    "            raise ValueError(f\"Weight shape {weight.shape} not compatible with input length {n_in}\")\n",
    "\n",
    "        # add bias (broadcast if needed)\n",
    "        out = out + bias\n",
    "        self.output = out\n",
    "        return out\n",
    "\n",
    "    def activate(self, func=\"relu\"):\n",
    "        if self.output is None:\n",
    "            raise ValueError(\"Run forward() before activate()\")\n",
    "        if func.lower() == \"relu\":\n",
    "            return np.maximum(0, self.output)\n",
    "        elif func.lower() == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-self.output))\n",
    "        elif func.lower() == \"softmax\":\n",
    "            exp_vals = np.exp(self.output - np.max(self.output))\n",
    "            return exp_vals / np.sum(exp_vals)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation function\")\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c4c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Input\n",
    "X = [5.1, 3.5, 1.4, 0.2]\n",
    "# Target Output\n",
    "Target_Output = [0.7, 0.2, 0.1]\n",
    "\n",
    "# First Hidden Layer\n",
    "W1 = [[0.2, 0.1, -0.4, 0.6],\n",
    "      [0.5, -0.2, 0.3, -0.1],\n",
    "      [-0.3, 0.4, 0.2, 0.5]]   # shape (3x4)\n",
    "\n",
    "B1 = [3.0, -2.1, 0.6]\n",
    "\n",
    "# Second Hidden Layer\n",
    "\n",
    "W2 = [[0.3, 0.7, -0.6],   \n",
    "      [-0.5, 0.2, 0.4]]   # shape (2x3)\n",
    "B2 = [4.3, 6.4]     \n",
    "\n",
    "\n",
    "# Output Layer (3 neurons = 3 classes)\n",
    "W3 = [[0.5, -0.2],\n",
    "      [-0.3, 0.6], \n",
    "      [0.8, -0.4]]   # shape (3x2)\n",
    "B3 = [-1.5, 2.1, -3.3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb34c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 output: [3.93 0.15 0.85]\n",
      "Layer 2 output: [0.994 0.992]\n",
      "Final Output (probabilities): [0.027 0.969 0.005]\n",
      "Loss: 0.351\n"
     ]
    }
   ],
   "source": [
    "layer1 = Dense_Layer(X, W1, B1)\n",
    "a1 = layer1.activate(\"relu\") if (layer1.forward() is not None) else None\n",
    "print(\"Layer 1 output:\", a1)\n",
    "\n",
    "# Layer 2\n",
    "layer2 = Dense_Layer(a1, W2, B2)\n",
    "a2 = layer2.activate(\"sigmoid\") if (layer2.forward() is not None) else None\n",
    "print(\"Layer 2 output:\", np.round(a2, 3))\n",
    "\n",
    "# Output Layer\n",
    "layer3 = Dense_Layer(a2, W3, B3)\n",
    "a3 = layer3.activate(\"softmax\") if (layer3.forward() is not None) else None\n",
    "print(\"Final Output (probabilities):\", np.round(a3, 3))\n",
    "\n",
    "# Loss\n",
    "loss_val = layer3.loss(Target_Output, a3)\n",
    "print(\"Loss:\", np.round(loss_val, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e167260",
   "metadata": {},
   "source": [
    "----------------------------------------------------------NUMBER 2----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1acc0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = [14.1, 20.3, 0.095]\n",
    "Target_Output2 = [1]\n",
    "\n",
    "we1 = [[0.5, 0.2, -0.7],\n",
    "       [-0.3, 0.4, 0.9],   #shape (3x3)\n",
    "       [0.8, -0.6, 0.1]]\n",
    "\n",
    "b1 = [0.3, -0.5, 0.6]\n",
    "\n",
    "we2 = np.array([[0.6, -0.3],\n",
    "                [-0.2, 0.5],\n",
    "                [0.4, 0.7]])   # shape (3,2)\n",
    "\n",
    "b2 = [4.3, 6.4]\n",
    "\n",
    "we3 = np.array([[0.7],\n",
    "                [-0.5]])   # shape (2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a34f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 output: [ 1.336  10.383   9.0095]\n",
      "Layer 2 output: [0.9938 0.9919]\n",
      "Final Output (probabilities): [0.231 0.917 0.052]\n",
      "Loss: 0.499\n"
     ]
    }
   ],
   "source": [
    "layer11 = Dense_Layer(X2, we1, b1)\n",
    "a11 = layer11.activate(\"relu\") if (layer11.forward() is not None) else None\n",
    "print(\"Layer 1 output:\", a11)\n",
    "\n",
    "# Layer 2\n",
    "layer22 = Dense_Layer(a11, we2, b2)\n",
    "a22 = layer22.activate(\"sigmoid\") if (layer22.forward() is not None) else None\n",
    "print(\"Layer 2 output:\", np.round(a2, 4) )\n",
    "\n",
    "# Output Layer\n",
    "layer33 = Dense_Layer(a22, we3, b3)\n",
    "a33 = layer3.activate(\"sigmoid\") if (layer33.forward() is not None) else None\n",
    "print(\"Final Output (probabilities):\", np.round(a33, 3))\n",
    "\n",
    "# Loss\n",
    "loss_val1 = layer3.loss(Target_Output2, a33)\n",
    "print(\"Loss:\", np.round(loss_val1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a2a0e",
   "metadata": {},
   "source": [
    "Yes â€” the network predicts Malignant (1).\n",
    "The final probability vector is [0.231, 0.917, 0.052] and the largest probability is 0.917 at index 1 - choose class 1 (Malignant)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
